{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPBsCPW7H2kQ",
        "outputId": "5521739f-21ee-4a0f-ff5c-c8b4ca6e7d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Available Provinces:\n",
            "ID: 1 - Name: Nanggroe Aceh Darussalam\n",
            "ID: 2 - Name: Sumatera Utara\n",
            "ID: 10 - Name: Kep. Riau\n",
            "ID: 4 - Name: Riau\n",
            "ID: 3 - Name: Sumatera Barat\n",
            "ID: 5 - Name: Jambi\n",
            "ID: 6 - Name: Sumatera Selatan\n",
            "ID: 9 - Name: Kep. Bangka Belitung\n",
            "ID: 7 - Name: Bengkulu\n",
            "ID: 8 - Name: Lampung\n",
            "ID: 34 - Name: Kalimantan Utara\n",
            "ID: 23 - Name: Kalimantan Timur\n",
            "ID: 20 - Name: Kalimantan Barat\n",
            "ID: 21 - Name: Kalimantan Tengah\n",
            "ID: 22 - Name: Kalimantan Selatan\n",
            "ID: 16 - Name: Banten\n",
            "ID: 11 - Name: DKI Jakarta\n",
            "ID: 12 - Name: Jawa Barat\n",
            "ID: 13 - Name: Jawa Tengah\n",
            "ID: 14 - Name: DI Yogyakarta\n",
            "ID: 15 - Name: Jawa Timur\n",
            "ID: 24 - Name: Sulawesi Utara\n",
            "ID: 25 - Name: Sulawesi Tengah\n",
            "ID: 28 - Name: Gorontalo\n",
            "ID: 29 - Name: Sulawesi Barat\n",
            "ID: 26 - Name: Sulawesi Selatan\n",
            "ID: 27 - Name: Sulawesi Tenggara\n",
            "ID: 17 - Name: Bali\n",
            "ID: 18 - Name: Nusa Tenggara Barat\n",
            "ID: 19 - Name: Nusa Tenggara Timur\n",
            "ID: 31 - Name: Maluku Utara\n",
            "ID: 33 - Name: Papua Barat\n",
            "ID: 32 - Name: Papua\n",
            "ID: 30 - Name: Maluku\n",
            "\n",
            "Enter Province ID: 33\n",
            "\n",
            "Available Regions:\n",
            "ID: 497 - Name: Kota Sorong\n",
            "ID: 488 - Name: Kab. Manokwari\n",
            "ID: 489 - Name: Kab. Fak Fak\n",
            "ID: 494 - Name: Kab. Kaimana\n",
            "\n",
            "Enter Region ID: 494\n",
            "\n",
            "Available Stations:\n",
            "ID: 97760 - Name: Stasiun Meteorologi Utarom\n",
            "\n",
            "Enter Station ID: 97760\n",
            "Enter the end date for predictions (DD-MM-YYYY): 04-01-2025\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "Predicted and added weather for: 2025-01-01\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Predicted and added weather for: 2025-01-02\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Predicted and added weather for: 2025-01-03\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Predicted and added weather for: 2025-01-04\n",
            "\n",
            "**Prediction Date:** 04-01-2025\n",
            "\n",
            "Min Temperature: 23.99\n",
            "Max Temperature: 30.49\n",
            "Average Temperature: 26.86\n",
            "Average Humidity: 82.63\n",
            "Rainfall: 14.16\n",
            "Sunshine Duration: 5.94\n",
            "Max Wind Speed: 5.04\n",
            "Wind Direction at Max Speed: 204.00\n",
            "Average Wind Speed: 2.33\n",
            "Most Wind Direction: SW\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from datetime import datetime, timedelta\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras.backend as K\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"data_until_2024.csv\")\n",
        "\n",
        "# Load saved encoders and scalers\n",
        "encoder = joblib.load(\"encoder2.pkl\")\n",
        "scaler_X = joblib.load(\"scaler_X2.pkl\")\n",
        "scaler_y = joblib.load(\"scaler_y2.pkl\")\n",
        "\n",
        "# Define custom MSE function for model loading\n",
        "def mse(y_true, y_pred):\n",
        "    return K.mean(K.square(y_true - y_pred))\n",
        "\n",
        "# Load trained model\n",
        "model = load_model(\"weather_forecasting_model2.h5\", custom_objects={\"mse\": mse})\n",
        "\n",
        "# Convert ID columns to numeric\n",
        "df[\"province_id\"] = pd.to_numeric(df[\"province_id\"], errors=\"coerce\")\n",
        "df[\"region_id\"] = pd.to_numeric(df[\"region_id\"], errors=\"coerce\")\n",
        "df[\"station_id\"] = pd.to_numeric(df[\"station_id\"], errors=\"coerce\")\n",
        "\n",
        "# Convert Date column and remove time component\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%Y\", errors='coerce')\n",
        "\n",
        "# Debugging: Check for any invalid dates\n",
        "if df[\"Date\"].isna().sum() > 0:\n",
        "    print(\"Warning: Some dates could not be converted! Check your dataset.\")\n",
        "    print(df[df[\"Date\"].isna()])\n",
        "\n",
        "# Ensure name columns exist (Modify if dataset has different column names)\n",
        "if \"province_name\" not in df.columns or \"region_name\" not in df.columns or \"station_name\" not in df.columns:\n",
        "    print(\"Error: Ensure dataset contains 'province_name', 'region_name', and 'station_name' columns!\")\n",
        "\n",
        "# Display available provinces with IDs and Names\n",
        "df_provinces = df[[\"province_id\", \"province_name\"]].drop_duplicates().dropna()\n",
        "print(\"\\nAvailable Provinces:\")\n",
        "for _, row in df_provinces.iterrows():\n",
        "    print(f\"ID: {int(row['province_id'])} - Name: {row['province_name']}\")\n",
        "\n",
        "# Step 1: Get Province ID\n",
        "while True:\n",
        "    try:\n",
        "        province_id = int(input(\"\\nEnter Province ID: \"))\n",
        "        if province_id in df_provinces[\"province_id\"].values:\n",
        "            province_name = df_provinces[df_provinces[\"province_id\"] == province_id][\"province_name\"].values[0]\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid Province ID! Please enter a valid one.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter a numeric value.\")\n",
        "\n",
        "# Display available regions with IDs and Names (Filtered by selected Province)\n",
        "df_regions = df[df[\"province_id\"] == province_id][[\"region_id\", \"region_name\"]].drop_duplicates().dropna()\n",
        "print(\"\\nAvailable Regions:\")\n",
        "for _, row in df_regions.iterrows():\n",
        "    print(f\"ID: {int(row['region_id'])} - Name: {row['region_name']}\")\n",
        "\n",
        "# Step 2: Get Region ID\n",
        "while True:\n",
        "    try:\n",
        "        region_id = int(input(\"\\nEnter Region ID: \"))\n",
        "        if region_id in df_regions[\"region_id\"].values:\n",
        "            region_name = df_regions[df_regions[\"region_id\"] == region_id][\"region_name\"].values[0]\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid Region ID! Please enter a valid one.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter a numeric value.\")\n",
        "\n",
        "# Display available stations with IDs and Names (Filtered by selected Region)\n",
        "df_stations = df[(df[\"province_id\"] == province_id) & (df[\"region_id\"] == region_id)][[\"station_id\", \"station_name\"]].drop_duplicates().dropna()\n",
        "print(\"\\nAvailable Stations:\")\n",
        "for _, row in df_stations.iterrows():\n",
        "    print(f\"ID: {int(row['station_id'])} - Name: {row['station_name']}\")\n",
        "\n",
        "# Step 3: Get Station ID\n",
        "while True:\n",
        "    try:\n",
        "        station_id = int(input(\"\\nEnter Station ID: \"))\n",
        "        if station_id in df_stations[\"station_id\"].values:\n",
        "            station_name = df_stations[df_stations[\"station_id\"] == station_id][\"station_name\"].values[0]\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid Station ID! Please enter a valid one.\")\n",
        "    except ValueError:\n",
        "        print(\"Please enter a numeric value.\")\n",
        "\n",
        "# Step 4: Get Date\n",
        "def get_user_input_date():\n",
        "    while True:\n",
        "        try:\n",
        "            input_date = input(\"Enter the end date for predictions (DD-MM-YYYY): \")\n",
        "            prediction_date = pd.to_datetime(input_date, format='%d-%m-%Y')\n",
        "            return prediction_date\n",
        "        except ValueError:\n",
        "            print(\"Invalid date format. Please enter the date in DD-MM-YYYY format.\")\n",
        "\n",
        "# 🔹 User-selected end date\n",
        "end_date = get_user_input_date()\n",
        "\n",
        "# Start prediction from 01-01-2025\n",
        "start_date = pd.to_datetime(\"01-01-2025\")\n",
        "\n",
        "df_filtered = df[(df[\"province_id\"] == province_id) &\n",
        "                 (df[\"region_id\"] == region_id) &\n",
        "                 (df[\"station_id\"] == station_id)]\n",
        "\n",
        "# Get the last 7 days of data before the target date\n",
        "df_last_7_days = df_filtered[(df_filtered[\"Date\"] < pd.to_datetime(\"01-01-2025\")) &\n",
        "                             (df_filtered[\"Date\"] >= pd.to_datetime(\"01-01-2025\") - pd.Timedelta(days=7))]\n",
        "\n",
        "# Sort by date to maintain chronological order\n",
        "df_last_7_days = df_last_7_days.sort_values(by=\"Date\")\n",
        "\n",
        "# Get latitude and longitude from the dataset for the selected station\n",
        "df[\"station_id\"] = pd.to_numeric(df[\"station_id\"], errors=\"coerce\")\n",
        "\n",
        "df_station = df_filtered[df_filtered[\"station_id\"] == station_id]\n",
        "station_info = df_station.iloc[0]  # Safe access\n",
        "latitude = station_info[\"latitude\"]\n",
        "longitude = station_info[\"longitude\"]\n",
        "\n",
        "\n",
        "# Create a list of the last 7 dates\n",
        "last_7_dates = [pd.to_datetime(\"01-01-2025\") - pd.Timedelta(days=i) for i in range(1, 8)]\n",
        "missing_dates = [date for date in last_7_dates if date not in df_last_7_days[\"Date\"].values]\n",
        "\n",
        "# Define numerical features (excluding latitude and longitude)\n",
        "numerical_features = [\"Min Temperature\", \"Max Temperature\", \"Average Temperature\",\n",
        "                      \"Average Humidity\", \"Rainfall\", \"Sunshine Duration\",\n",
        "                      \"Max Wind Speed\", \"Wind Direction at Max Speed\",\n",
        "                      \"Average Wind Speed\"]\n",
        "\n",
        "# Store new data in a list for later concatenation\n",
        "new_data_list = []\n",
        "\n",
        "# Handle missing dates using forward fill, and fallback to backward fill if needed\n",
        "for missing_date in missing_dates:\n",
        "    # Try forward fill - look for the latest previous day with data\n",
        "    previous_day = missing_date - timedelta(days=1)\n",
        "    prev_data_row = None\n",
        "\n",
        "    while previous_day >= df_last_7_days[\"Date\"].min():\n",
        "        prev_data_row = df_last_7_days[df_last_7_days[\"Date\"] == previous_day]\n",
        "        if not prev_data_row.empty:\n",
        "            break\n",
        "        previous_day -= timedelta(days=1)\n",
        "\n",
        "    # If forward fill failed, try backward fill - look for the next available date\n",
        "    if prev_data_row is None or prev_data_row.empty:\n",
        "        next_day = missing_date + timedelta(days=1)\n",
        "        while next_day <= df_last_7_days[\"Date\"].max():\n",
        "            prev_data_row = df_last_7_days[df_last_7_days[\"Date\"] == next_day]\n",
        "            if not prev_data_row.empty:\n",
        "                break\n",
        "            next_day += timedelta(days=1)\n",
        "\n",
        "    # If both forward and backward fill fail, skip this missing date\n",
        "    if prev_data_row is None or prev_data_row.empty:\n",
        "        print(f\"⚠️ No data available to fill missing date: {missing_date.strftime('%d-%m-%Y')}\")\n",
        "        continue\n",
        "\n",
        "    # Copy the found day's values and assign the missing date\n",
        "    new_data = prev_data_row.iloc[0].copy()\n",
        "    new_data[\"Date\"] = missing_date\n",
        "    new_data_list.append(new_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert new data list to DataFrame\n",
        "if new_data_list:\n",
        "    new_data_df = pd.DataFrame(new_data_list)\n",
        "    df_last_7_days = pd.concat([df_last_7_days, new_data_df], ignore_index=True)\n",
        "\n",
        "# Convert Date column to datetime again (in case new rows were added)\n",
        "df_last_7_days[\"Date\"] = pd.to_datetime(df_last_7_days[\"Date\"])\n",
        "\n",
        "# Sort data again after adding new rows\n",
        "df_last_7_days = df_last_7_days.sort_values(by=\"Date\")\n",
        "\n",
        "numerical_features = [\"Min Temperature\", \"Max Temperature\", \"Average Temperature\",\n",
        "                      \"Average Humidity\", \"Rainfall\", \"Sunshine Duration\",\n",
        "                      \"Max Wind Speed\", \"Wind Direction at Max Speed\",\n",
        "                      \"Average Wind Speed\", \"latitude\", \"longitude\",\n",
        "                      \"region_id\", \"province_id\", \"station_id\"]\n",
        "\n",
        "from datetime import timedelta\n",
        "\n",
        "while df_last_7_days[\"Date\"].max() < end_date:\n",
        "    # -------- Prepare Input --------\n",
        "    X_input_numerical = df_last_7_days[numerical_features]\n",
        "\n",
        "    wind_direction_encoded = encoder.transform(df_last_7_days[[\"Most Wind Direction\"]])\n",
        "    wind_direction_df = pd.DataFrame(wind_direction_encoded, columns=encoder.get_feature_names_out([\"Most Wind Direction\"]))\n",
        "\n",
        "    X_input_df = pd.concat([X_input_numerical.reset_index(drop=True), wind_direction_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    X_input_df['Year'] = df_last_7_days['Date'].dt.year.values\n",
        "    X_input_df['Month'] = df_last_7_days['Date'].dt.month.values\n",
        "    X_input_df['Day'] = df_last_7_days['Date'].dt.day.values\n",
        "    X_input_df['DayOfWeek'] = df_last_7_days['Date'].dt.dayofweek.values\n",
        "\n",
        "    X_input_scaled = scaler_X.transform(X_input_df)\n",
        "    X_input_reshaped = X_input_scaled.reshape(1, 7, X_input_scaled.shape[1])\n",
        "\n",
        "    # -------- Predict Next Day --------\n",
        "    prediction_date = df_last_7_days[\"Date\"].max() + timedelta(days=1)\n",
        "\n",
        "    predicted_weather = model.predict(X_input_reshaped)\n",
        "    predicted_weather_original = scaler_y.inverse_transform(predicted_weather)\n",
        "\n",
        "    num_encoded_features = wind_direction_encoded.shape[1]\n",
        "    predicted_weather_numerical = predicted_weather_original[:, :-num_encoded_features]\n",
        "    predicted_weather_wind_direction = predicted_weather_original[:, -num_encoded_features:]\n",
        "\n",
        "    predicted_wind_direction = encoder.inverse_transform(predicted_weather_wind_direction)\n",
        "\n",
        "    # -------- Construct Predicted Row --------\n",
        "    predicted_row = {\n",
        "        \"Date\": prediction_date,\n",
        "        \"province_id\": df_last_7_days[\"province_id\"].iloc[-1],\n",
        "        \"region_id\": df_last_7_days[\"region_id\"].iloc[-1],\n",
        "        \"station_id\": df_last_7_days[\"station_id\"].iloc[-1],\n",
        "        \"latitude\": df_last_7_days[\"latitude\"].iloc[-1],\n",
        "        \"longitude\": df_last_7_days[\"longitude\"].iloc[-1],\n",
        "        \"Most Wind Direction\": predicted_wind_direction[0][0]\n",
        "    }\n",
        "\n",
        "    for name, value in zip(target_columns, predicted_weather_numerical[0]):\n",
        "        predicted_row[name] = round(value, 2)\n",
        "\n",
        "    # -------- Update Dataset --------\n",
        "    df_last_7_days = pd.concat([df_last_7_days, pd.DataFrame([predicted_row])], ignore_index=True)\n",
        "    df_last_7_days = df_last_7_days.sort_values(\"Date\").reset_index(drop=True)\n",
        "    df_last_7_days = df_last_7_days.iloc[1:]  # drop the oldest row to maintain 7-day window\n",
        "\n",
        "    print(f\"Predicted and added weather for: {prediction_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "# After the while-loop finishes\n",
        "# The last row in df_last_7_days will be for end_date\n",
        "final_row = df_last_7_days[df_last_7_days[\"Date\"] == end_date].copy()\n",
        "\n",
        "# Select the same features for decoding\n",
        "X_numerical = final_row[numerical_features]\n",
        "X_wind_encoded = encoder.transform(final_row[[\"Most Wind Direction\"]])\n",
        "X_wind_decoded = encoder.inverse_transform(X_wind_encoded)\n",
        "\n",
        "# Print the values\n",
        "print(f\"\\n**Prediction Date:** {end_date.strftime('%d-%m-%Y')}\\n\")\n",
        "for name in target_columns:\n",
        "    print(f\"{name}: {final_row[name].values[0]:.2f}\")\n",
        "\n",
        "# Print decoded wind direction\n",
        "print(f\"Most Wind Direction: {X_wind_decoded[0][0]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F38Eomn8lvcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}